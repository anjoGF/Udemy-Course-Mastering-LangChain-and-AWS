{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Udemy LangChain SQLite Setup Notebook\n",
        "\n",
        "This repository hosts the Jupyter notebook `Udemy_LangChain_SQLite_Setup.ipynb`, a comprehensive guide designed for developers, analysts, architects and ML engineers exploring the integration of LangChain with SQLite databases for data analysis. The notebook is a practical demonstration of using natural language queries to interact with SQL databases, leveraging LangChain's capabilities for enhanced data analysis in the financial sector.\n",
        "\n",
        "## Features\n",
        "\n",
        "- **LangChain and SQLite Integration**: Demonstrates how to use LangChain with SQLite for querying and analyzing financial data using natural language.\n",
        "- **Financial Data Analysis**: Focuses on financial data, providing insights into economic indicators, yield curve prices, production data, and business cycles.\n",
        "- **Practical Examples**: Includes examples of SQL queries for data insertion, schema creation, and advanced data analysis techniques.\n",
        "- **Comprehensive Setup**: Guides through the setup process for LangChain, SQLite, and necessary Python packages.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Python 3.x installed on your system.\n",
        "- Jupyter Notebook or Jupyter Lab for running notebook files.\n",
        "- Basic knowledge of SQL, Python programming, and financial datasets.\n",
        "\n",
        "## Installation\n",
        "\n",
        "1. **Clone the Repository**: Clone this repository to your local machine to get access to the notebook and related files.\n",
        "\n",
        "    ```bash\n",
        "    git clone https://github.com/anjoGF/Medium_LangChain_Demo.git\n",
        "    ```\n",
        "\n",
        "2. **Install Dependencies**: Install the required Python packages using pip. The notebook includes a section with pip commands to install packages such as `pandas`, `sqlite3`, `openai`, `langchain`, and others.\n",
        "\n",
        "    ```bash\n",
        "    pip install pandas sqlite3 openai langchain langchain-experimental pandas-datareader plotly redis faiss-cpu SQLAlchemy python-dotenv\n",
        "    ```\n",
        "\n",
        "3. **Set Up SQLite Database**: Follow the instructions within the notebook to set up your SQLite database, create tables, and insert sample data for analysis.\n",
        "\n",
        "4. **Configure OpenAI API Key**: Ensure you have an OpenAI API key and set it up as shown in the notebook to use LangChain's features.\n",
        "\n",
        "## Usage\n",
        "\n",
        "- Open the `Udemy_LangChain_SQLite_Setup.ipynb` notebook in Jupyter Notebook/Lab.\n",
        "- Follow the step-by-step instructions to explore LangChain's integration with SQLite.\n",
        "- Use the provided SQL queries and modify them as needed to analyze your financial datasets.\n",
        "\n",
        "## Contributing\n",
        "\n",
        "Contributions to improve the notebook or add more examples are welcome. Please feel free to fork the repository, make your changes, and submit a pull request.\n",
        "\n",
        "## License\n",
        "\n",
        "This project is licensed under the MIT License. See the LICENSE file in the repository for more information.\n",
        "\n",
        "## Contact\n",
        "\n",
        "For any queries or further assistance, please open an issue in the GitHub repository."
      ],
      "metadata": {
        "id": "rDZqcrxYUKH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setting Up the Environment**\n",
        "\n",
        "Before diving into the data analysis, it's essential to set up our environment by installing all necessary Python packages. This includes `pandas` for data manipulation, `sqlite3` for interacting with SQLite databases, `openai` and `langchain` for leveraging LangChain's capabilities, and other packages that will be used throughout this notebook.\n",
        "\n",
        "Run the following command to install the required packages:\n"
      ],
      "metadata": {
        "id": "l5FUc5Q2zb8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install pandas\n",
        "pip install scikit-learn\n",
        "pip install pandas-datareader\n",
        "pip install plotly redis\n",
        "pip install langchain langchain-experimental\n",
        "pip install openai\n",
        "pip install tiktoken\n",
        "pip install faiss-cpu\n",
        "pip install openai\n",
        "pip install SQLAlchemy\n",
        "pip install load_dotenv"
      ],
      "metadata": {
        "id": "0wimXe7QtP9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to LangChain and SQLite Integration**\n",
        "\n",
        "This section introduces the concept of integrating LangChain with SQLite databases for financial data analysis. LangChain allows for querying and analyzing data using natural language, making it a powerful tool for AI architects and ML engineers. This notebook demonstrates how to set up LangChain and SQLite for financial data analysis, including the installation of necessary Python packages and the configuration of the OpenAI API key.\n"
      ],
      "metadata": {
        "id": "HRKBSiRKyxUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY=\"your-api-key\""
      ],
      "metadata": {
        "id": "tltw3jlVEOzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Section 3: Creating the SQLite Database\n",
        "\n",
        "### **Creating the SQLite Database**\n",
        "\n",
        "In this section, we will create an SQLite database and define the schema for our financial data analysis. This involves creating tables for economic indicators, yield curve prices, production data, and business cycles. We will also insert some sample data into these tables to be used in our analysis. Follow the code blocks below to create your SQLite database and tables.\n"
      ],
      "metadata": {
        "id": "x48ghE7zz0UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "def create_tables(db_name):\n",
        "    with sqlite3.connect(db_name) as conn:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Create economic indicators table with consistent date column name\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS economic_indicators (\n",
        "                Date TEXT PRIMARY KEY,\n",
        "                UNRATE REAL,\n",
        "                PAYEMS REAL,\n",
        "                ICSA REAL,\n",
        "                CIVPART REAL,\n",
        "                INDPRO REAL\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Create yield_curve_prices table with consistent date column name\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS yield_curve_prices (\n",
        "                Date TEXT PRIMARY KEY,\n",
        "                DGS1MO REAL,\n",
        "                DGS3MO REAL,\n",
        "                DGS6MO REAL,\n",
        "                DGS1 REAL,\n",
        "                DGS2 REAL,\n",
        "                DGS3 REAL,\n",
        "                DGS5 REAL,\n",
        "                DGS7 REAL,\n",
        "                DGS10 REAL,\n",
        "                DGS20 REAL,\n",
        "                DGS30 REAL\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Create production_data table with consistent date column name\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS production_data (\n",
        "                Date TEXT PRIMARY KEY,\n",
        "                SAUNGDPMOMBD REAL,\n",
        "                ARENGDPMOMBD REAL,\n",
        "                IRNNGDPMOMBD REAL,\n",
        "                SAUNXGO REAL,\n",
        "                QATNGDPMOMBD REAL,\n",
        "                KAZNGDPMOMBD REAL,\n",
        "                IRQNXGO REAL,\n",
        "                IRNNXGO REAL,\n",
        "                KWTNGDPMOMBD REAL,\n",
        "                IPN213111S REAL,\n",
        "                PCU213111213111 REAL,\n",
        "                DPCCRV1Q225SBEA REAL\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Create business_cycles table with an auto-increment ID as the primary key\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS business_cycles (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                Peak_Month TEXT,\n",
        "                Trough_Month TEXT,\n",
        "                Start_Date TEXT,\n",
        "                End_Date TEXT,\n",
        "                Phase TEXT\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Optionally, add indexes on date columns if they will be used in joins or queries often\n",
        "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_econ_date ON economic_indicators (Date)')\n",
        "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_yield_date ON yield_curve_prices (Date)')\n",
        "        cursor.execute('CREATE INDEX IF NOT EXISTS idx_prod_date ON production_data (Date)')\n",
        "\n",
        "        print(\"Tables created successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_tables(\"financial_data.db\")"
      ],
      "metadata": {
        "id": "dD1VzI70rtFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca783ede-0e7d-4eae-ffd9-f2fdde38e3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Inserting Data into the Database**\n",
        "\n",
        "After setting up our database schema, the next step is to populate the tables with data. This section provides SQL commands for inserting sample data into each table. This data will serve as the foundation for our financial data analysis using LangChain and natural language queries. Ensure you have the necessary data ready and follow the instructions to insert it into your database.\n"
      ],
      "metadata": {
        "id": "3HTXPBzG0If-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_business_cycle_data(db_name):\n",
        "    business_cycles = [\n",
        "        {\"peak\": \"1999-03-01\", \"trough\": \"2001-03-01\", \"start\": \"1999-03-01 00:00:00\", \"end\": \"2001-03-01 00:00:00\", \"phase\": \"Expansion\"},\n",
        "        {\"peak\": \"2001-03-01\", \"trough\": \"2001-11-01\", \"start\": \"2001-03-01 00:00:00\", \"end\": \"2001-11-01 00:00:00\", \"phase\": \"Contraction\"},\n",
        "        {\"peak\": \"2001-11-01\", \"trough\": \"2007-12-01\", \"start\": \"2001-11-01 00:00:00\", \"end\": \"2007-12-01 00:00:00\", \"phase\": \"Expansion\"},\n",
        "        {\"peak\": \"2007-12-01\", \"trough\": \"2009-06-01\", \"start\": \"2007-12-01 00:00:00\", \"end\": \"2009-06-01 00:00:00\", \"phase\": \"Contraction\"},\n",
        "        {\"peak\": \"2020-02-01\", \"trough\": \"2020-04-01\", \"start\": \"2009-06-01 00:00:00\", \"end\": \"2020-02-01 00:00:00\", \"phase\": \"Expansion\"},\n",
        "        {\"peak\": \"2020-02-01\", \"trough\": \"2020-04-01\", \"start\": \"2020-02-01 00:00:00\", \"end\": \"2020-04-01 00:00:00\", \"phase\": \"Contraction\"},\n",
        "        {\"peak\": \"2021-12-01\", \"trough\": \"2022-03-31\", \"start\": \"2020-04-01 00:00:00\", \"end\": \"2022-03-11 00:00:00\", \"phase\": \"Expansion\"}\n",
        "    ]\n",
        "    with sqlite3.connect(db_name) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        for cycle in business_cycles:\n",
        "            cursor.execute('''\n",
        "                INSERT INTO business_cycles (Peak_Month, Trough_Month, Start_Date, End_Date, Phase)\n",
        "                VALUES (?, ?, ?, ?, ?)\n",
        "            ''', (cycle[\"peak\"], cycle[\"trough\"], cycle[\"start\"], cycle[\"end\"], cycle[\"phase\"]))\n",
        "        print(\"Business cycle data inserted successfully.\")\n",
        "\n",
        "insert_business_cycle_data(\"financial_data.db\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I80axfDdEObe",
        "outputId": "f00acf7c-b43d-44e4-d5e3-55247fe9c04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business cycle data inserted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas_datareader.data as web\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, db_name=\"financial_data.db\"):\n",
        "        self.db_name = db_name\n",
        "        self.economic_indicators_tickers = ['UNRATE', 'PAYEMS', 'ICSA', 'CIVPART', 'INDPRO']\n",
        "        self.yield_curve_tickers = ['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3', 'DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30']\n",
        "        self.production_data_tickers = ['SAUNGDPMOMBD', 'ARENGDPMOMBD', 'IRNNGDPMOMBD', 'SAUNXGO','DPCCRV1Q225SBEA',\n",
        "                                        'QATNGDPMOMBD', 'KAZNGDPMOMBD', 'IRQNXGO', 'IRNNXGO', 'KWTNGDPMOMBD', 'IPN213111S', 'PCU213111213111']\n",
        "\n",
        "    def clean_data(self, data):\n",
        "        # Function to clean data, remove leading/trailing single quotes, and convert to numeric\n",
        "        cleaned_data = data.applymap(lambda x: x.strip(\"'\") if isinstance(x, str) else x)\n",
        "        cleaned_data = cleaned_data.apply(pd.to_numeric, errors='coerce')\n",
        "        return cleaned_data\n",
        "\n",
        "    def fetch_and_insert_data(self, tickers, table_name):\n",
        "        start_date = '2000-12-31'\n",
        "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
        "        try:\n",
        "            data = web.DataReader(tickers, 'fred', start_date, end_date)\n",
        "            data = data.interpolate(method='quadratic').bfill().ffill()\n",
        "            data = data.resample('D').ffill().bfill()\n",
        "\n",
        "            # Clean the data to handle formatting issues\n",
        "            data = self.clean_data(data)\n",
        "\n",
        "            # Convert the index (which is the date) to the correct format\n",
        "            data.index = pd.to_datetime(data.index).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "            with sqlite3.connect(self.db_name) as conn:\n",
        "                data.to_sql(table_name, conn, if_exists='replace', index_label='Date')\n",
        "            print(f\"Data inserted into {table_name} table\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch and insert the data: {e}\")\n",
        "\n",
        "def main():\n",
        "    db_name = \"financial_data.db\"\n",
        "    loader = DataLoader(db_name)\n",
        "    loader.fetch_and_insert_data(loader.economic_indicators_tickers, 'economic_indicators')\n",
        "    loader.fetch_and_insert_data(loader.yield_curve_tickers, 'yield_curve_prices')\n",
        "    loader.fetch_and_insert_data(loader.production_data_tickers, 'production_data')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMYrWUbrEOe4",
        "outputId": "f44be811-40df-4f7b-ccc8-1eb1dd7f4fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inserted into economic_indicators table\n",
            "Data inserted into yield_curve_prices table\n",
            "Data inserted into production_data table\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Database name\n",
        "db_name = \"financial_data.db\"\n",
        "\n",
        "# Connect to the SQLite database\n",
        "conn = sqlite3.connect(db_name)\n",
        "\n",
        "# Fetch data from economic_indicators table\n",
        "economic_indicators_query = \"SELECT * FROM economic_indicators\"\n",
        "economic_indicators_df = pd.read_sql(economic_indicators_query, conn)\n",
        "print(\"Economic Indicators Data:\\n\", economic_indicators_df.head())\n",
        "\n",
        "# # Fetch data from yield_curve_prices table\n",
        "yield_curve_prices_query = \"SELECT * FROM yield_curve_prices\"\n",
        "yield_curve_prices_df = pd.read_sql(yield_curve_prices_query, conn)\n",
        "print(\"\\nYield Curve Prices Data:\\n\", yield_curve_prices_df.head())\n",
        "yield_curve_prices_df.to_csv('prices.csv')\n",
        "\n",
        "# Fetch data from production_data table\n",
        "production_data_query = \"SELECT * FROM production_data\"\n",
        "production_data_df = pd.read_sql(production_data_query, conn)\n",
        "print(\"\\nProduction Data:\\n\", production_data_df.head())\n",
        "\n",
        "# Fetch data from business_cycles table\n",
        "business_cycles_query = \"SELECT * FROM business_cycles\"\n",
        "business_cycles_df = pd.read_sql(business_cycles_query, conn)\n",
        "print(\"\\nBusiness Cycles Data:\\n\", business_cycles_df.head())\n",
        "\n",
        "# Close the database connection\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "N-SLyvgFEOho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Querying the Database with Natural Language**\n",
        "\n",
        "Now that our environment is set up, and our database is populated with data, we can start querying it using natural language thanks to LangChain. This section demonstrates how to construct natural language queries to extract insights from our financial data. We'll explore various examples, showing how LangChain translates these queries into SQL commands and retrieves the relevant data from our SQLite database.\n"
      ],
      "metadata": {
        "id": "pvxQm_up0R5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.utilities import SQLDatabase\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "API_KEY=OPENAI_API_KEY\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "# initialize our SQL Database\n",
        "db_uri = \"sqlite:///financial_data.db\"\n",
        "db = SQLDatabase.from_uri(db_uri)\n",
        "\n",
        "llm = OpenAI(openai_api_key=API_KEY, temperature=0, verbose=True)\n",
        "\n",
        "# Create our SQL Chain instance for building our SQL Queries\n",
        "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True)\n",
        "\n",
        "# please replace this query with your own question\n",
        "natural_language_question = \"List the yield curve values on 8/29/2006 00:00:00.\"\n",
        "\n",
        "# Generate the query\n",
        "response = db_chain.run(natural_language_question)\n",
        "print(\"Response\", response)"
      ],
      "metadata": {
        "id": "zOysj8kDhw0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d6cb4ff-317d-47a4-a7c8-6a318ed6a237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "List the yield curve values on 8/29/2006 00:00:00.\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT \"DGS1MO\", \"DGS3MO\", \"DGS6MO\", \"DGS1\", \"DGS2\", \"DGS3\", \"DGS5\", \"DGS7\", \"DGS10\", \"DGS20\", \"DGS30\" FROM yield_curve_prices WHERE \"Date\" = '2006-08-29 00:00:00' LIMIT 5;\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[(5.19, 5.07, 5.16, 5.06, 4.87, 4.79, 4.77, 4.77, 4.79, 5.0, 4.93)]\u001b[0m\n",
            "Answer:\u001b[32;1m\u001b[1;3m5.19, 5.07, 5.16, 5.06, 4.87, 4.79, 4.77, 4.77, 4.79, 5.0, 4.93\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Response 5.19, 5.07, 5.16, 5.06, 4.87, 4.79, 4.77, 4.77, 4.79, 5.0, 4.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Leveraging LangChain for Advanced SQL Queries**\n",
        "\n",
        "In this section, we explore how to utilize LangChain to create an SQL agent capable of interpreting and executing SQL queries based on natural language input. This powerful feature allows users to interact with the SQLite database using conversational language, making data analysis more accessible and intuitive.\n",
        "\n",
        "## **Creating the SQL Agent**\n",
        "\n",
        "The `create_sql_agent` function initializes an SQL agent with specified properties, enabling the execution of SQL queries derived from natural language descriptions. The agent leverages a language model (provided by OpenAI) and a toolkit (`SQLDatabaseToolkit`) containing tools for query creation, execution, syntax checking, and more. The agent is configured to be verbose for detailed logging and is set to the `ZERO_SHOT_REACT_DESCRIPTION` type, indicating its ability to understand and react to descriptions in a zero-shot learning context.\n",
        "\n",
        "## **Custom Date Formatting Tool**\n",
        "\n",
        "To enhance the agent's capabilities, we introduce a custom tool for date formatting (`DateFormatTool`). This tool ensures that dates mentioned in queries are correctly formatted to match the database schema ('YYYY-MM-DD 00:00:00'), allowing for precise data retrieval based on date-specific queries.\n",
        "\n",
        "## **Example Query Execution**\n",
        "\n",
        "We demonstrate the SQL agent's functionality by executing a sample query: retrieving yield curve values for a specific date. This showcases the agent's ability to translate natural language questions into SQL commands and fetch the relevant data from the database.\n",
        "\n"
      ],
      "metadata": {
        "id": "9_50x77-rD18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.agents.agent_types import AgentType\n",
        "\n",
        "# Create an SQL Agent\n",
        "\"\"\"\n",
        "create_sql_agent Function:\n",
        "- Function Purpose: Initializes an SQL agent. The method creates an agent with specified properties.\n",
        "- Parameters Explained:\n",
        "  - llm: The language model being used, in this case, provided by OpenAI.\n",
        "  - toolkit: The SQLDatabaseToolkit, which contains tools for query creation, execution, syntax checking, and more.\n",
        "  - verbose: A boolean flag to enable detailed logging.\n",
        "  - agent_type: Specifies the type of agent. Here 'ZERO_SHOT_REACT_DESCRIPTION' implies the agent's capability to understand and react to descriptions in a zero-shot learning context.\n",
        "\"\"\"\n",
        "\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
        "    verbose = True,\n",
        "    agent_type = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    top_k=10\n",
        "\n",
        ")\n",
        "\n",
        "## Example query to query the SQL Agent\n",
        "query_result = agent_executor.run(\n",
        "    \"List the yield curve values on 8/29/2006 00:00:00.\"\n",
        ")\n",
        "\n",
        "print(\"query result:\", query_result)\n",
        "\n",
        "# Close the connection\n",
        "conn = sqlite3.connect(db_name)\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAGLmYa6dSDe",
        "outputId": "d5156f7b-ef4d-48a7-f407-f75f83811ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input: \u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, economic_indicators, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table.\n",
            "Action: sql_db_schema\n",
            "Action Input: yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TEXT, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table for the values on 8/29/2006 00:00:00.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT * FROM yield_curve_prices WHERE Date = '2006-08-29 00:00:00'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[('2006-08-29 00:00:00', 5.19, 5.07, 5.16, 5.06, 4.87, 4.79, 4.77, 4.77, 4.79, 5.0, 4.93)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: [('2006-08-29 00:00:00', 5.19, 5.07, 5.16, 5.06, 4.87, 4.79, 4.77, 4.77, 4.79, 5.0, 4.93)]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "query result: [('2006-08-29 00:00:00', 5.19, 5.07, 5.16, 5.06, 4.87, 4.79, 4.77, 4.77, 4.79, 5.0, 4.93)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "chKwlKTE57o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utilities import SQLDatabase\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.agents.agent_types import AgentType\n",
        "\n",
        "agent_executor.run(\"Describe the data in the production_data table.\")"
      ],
      "metadata": {
        "id": "IWaE4cAoqTqR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "e6c97eb3-b0f1-4bf3-e120-670ec2188477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input: \u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, economic_indicators, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the schema of the production_data table.\n",
            "Action: sql_db_schema\n",
            "Action Input: production_data\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE production_data (\n",
            "\t\"Date\" TEXT, \n",
            "\t\"SAUNGDPMOMBD\" REAL, \n",
            "\t\"ARENGDPMOMBD\" REAL, \n",
            "\t\"IRNNGDPMOMBD\" REAL, \n",
            "\t\"SAUNXGO\" REAL, \n",
            "\t\"DPCCRV1Q225SBEA\" REAL, \n",
            "\t\"QATNGDPMOMBD\" REAL, \n",
            "\t\"KAZNGDPMOMBD\" REAL, \n",
            "\t\"IRQNXGO\" REAL, \n",
            "\t\"IRNNXGO\" REAL, \n",
            "\t\"KWTNGDPMOMBD\" REAL, \n",
            "\t\"IPN213111S\" REAL, \n",
            "\t\"PCU213111213111\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from production_data table:\n",
            "Date\tSAUNGDPMOMBD\tARENGDPMOMBD\tIRNNGDPMOMBD\tSAUNXGO\tDPCCRV1Q225SBEA\tQATNGDPMOMBD\tKAZNGDPMOMBD\tIRQNXGO\tIRNNXGO\tKWTNGDPMOMBD\tIPN213111S\tPCU213111213111\n",
            "2001-01-01\t7890000.0\t2120000.0\t3571700.0\t7118438.3562\t2.6\t680000.0\t806469.863\t1453907.5448\t2456136.2948\t1745865.7534\t116.4692\t159.6\n",
            "2001-01-02\t7890000.0\t2120000.0\t3571700.0\t7118438.3562\t2.6\t680000.0\t806469.863\t1453907.5448\t2456136.2948\t1745865.7534\t116.4692\t159.6\n",
            "2001-01-03\t7890000.0\t2120000.0\t3571700.0\t7118438.3562\t2.6\t680000.0\t806469.863\t1453907.5448\t2456136.2948\t1745865.7534\t116.4692\t159.6\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should limit the results to 10 rows.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT * FROM production_data LIMIT 10\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[('2001-01-01', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-02', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-03', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-04', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-05', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-06', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-07', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-08', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-09', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-10', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: [('2001-01-01', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-02', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-03', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.294\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[('2001-01-01', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-02', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-03', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.294\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build a custom tool**"
      ],
      "metadata": {
        "id": "qoKMt14qA31Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dateutil"
      ],
      "metadata": {
        "id": "vGdOjZfamGYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "from langchain.utilities import SQLDatabase\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.tools import AIPluginTool\n",
        "from langchain.agents import Tool\n",
        "from datetime import datetime\n",
        "from dateutil.parser import parse\n",
        "from dateutil import parser\n",
        "from datetime import datetime\n",
        "from langchain.agents import Tool\n",
        "\n",
        "# Custom function to format date\n",
        "def format_date_for_db(query_date: str):\n",
        "    try:\n",
        "        # Use dateutil.parser to parse the date from various formats\n",
        "        date_obj = parser.parse(query_date)\n",
        "        # Format the date to match the database format (e.g., 'YYYY-MM-DD 00:00:00')\n",
        "        formatted_date = date_obj.strftime(\"%Y-%m-%d 00:00:00\")\n",
        "        return formatted_date\n",
        "    except ValueError as e:\n",
        "        # Handle the error if the date format is incorrect\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Create a custom tool for date formatting\n",
        "date_format_tool = Tool(\n",
        "    name=\"DateFormatTool\",\n",
        "    func=format_date_for_db,\n",
        "    description=\"Formats the date to match the database format 'YYYY-MM-DD 00:00:00'.\"\n",
        ")\n",
        "\n",
        "# Example usage\n",
        "formatted_date = date_format_tool.run(\"December 10th 2006\")\n",
        "print(formatted_date)  # Output: \"2006-12-10 00:00:00\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIur7FrkA8Xo",
        "outputId": "30198e1b-6791-4402-d449-ce4dbbf6b19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2006-12-10 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_date_for_db(query_date: str):\n",
        "    try:\n",
        "        # Use dateutil.parser to parse the date from various formats\n",
        "        date_obj = parser.parse(query_date)\n",
        "        # Format the date to match the database format (e.g., 'YYYY-MM-DD 00:00:00')\n",
        "        formatted_date = date_obj.strftime(\"%Y-%m-%d 00:00:00\")\n",
        "        return formatted_date\n",
        "    except ValueError as e:\n",
        "        # Handle the error if the date format is incorrect\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "\n",
        "date_format_tool = Tool(name=\"DateFormatTool\",func=format_date_for_db, description=\"Formats the date to match the database format 'YYYY-MM-DD 00:00:00'.\")"
      ],
      "metadata": {
        "id": "yz5LJZZ8DbDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.utilities import SQLDatabase\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from langchain.agents.agent_toolkits import create_retriever_tool\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "API_KEY = OPENAI_API_KEY\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "# Initialize the SQLite database\n",
        "db_uri = \"sqlite:///financial_data.db\"\n",
        "db = SQLDatabase.from_uri(db_uri)\n",
        "\n",
        "# Initialize the LangChain LLM with OpenAI\n",
        "llm = OpenAI(openai_api_key=API_KEY, temperature=0, verbose=True)\n",
        "tools = load_tools([\"requests_all\"])\n",
        "# Define few-shot examples specific to your database\n",
        "few_shots = {\n",
        "    \"What was the highest unemployment rate last year?\": \"SELECT MAX(UNRATE) FROM economic_indicators WHERE Date >= '2022-01-01 00:00:00' AND Date <= '2022-12-31 00:00:00';\",\n",
        "    \"Average industrial production for the previous month?\": \"SELECT AVG(IPN213111S) FROM production_data WHERE Date >= date('now', 'start of month', '-1 month', '00:00:00') AND Date < date('now', 'start of month', '00:00:00');\",\n",
        "    \"Show the five lowest 10-year yield rates of the current year.\": \"SELECT DGS10 FROM yield_curve_prices WHERE Date >= '2023-01-01 00:00:00' ORDER BY DGS10 ASC LIMIT 5;\",\n",
        "    \"List the economic indicators for the first quarter of 2023.\": \"SELECT * FROM economic_indicators WHERE Date >= '2023-01-01 00:00:00' AND Date <= '2023-03-31 00:00:00';\",\n",
        "    \"What are the latest available production numbers for Saudi Arabia?\": \"SELECT SAUNGDPMOMBD FROM production_data WHERE Date = (SELECT MAX(Date) FROM production_data);\",\n",
        "    \"Compare the unemployment rate at the beginning and end of the last recession.\": \"SELECT UNRATE FROM economic_indicators WHERE Date IN (SELECT Start_Date FROM business_cycles WHERE Phase = 'Contraction' ORDER BY Start_Date DESC LIMIT 1) OR Date IN (SELECT End_Date FROM business_cycles WHERE Phase = 'Contraction' ORDER BY End_Date DESC LIMIT 1);\",\n",
        "    \"Find the average civilian labor force participation rate for the last year.\": \"SELECT AVG(CIVPART) FROM economic_indicators WHERE Date >= '2022-01-01 00:00:00' AND Date <= '2022-12-31 00:00:00';\",\n",
        "    \"Show the change in 2-year yield rates over the past six months.\": \"SELECT DGS2 FROM yield_curve_prices WHERE Date >= date('now', '-6 months', '00:00:00') ORDER BY Date;\",\n",
        "    \"What was the maximum production of natural gas in Qatar last year?\": \"SELECT MAX(QATNGDPMOMBD) FROM production_data WHERE Date >= '2022-01-01 00:00:00' AND Date <= '2022-12-31 00:00:00';\",\n",
        "    \"List the top 3 longest economic expansions since 2000.\": \"SELECT Start_Date, End_Date FROM business_cycles WHERE Phase = 'Expansion' AND Start_Date >= '2000-01-01 00:00:00' ORDER BY (julianday(End_Date) - julianday(Start_Date)) DESC LIMIT 3;\"\n",
        "}\n",
        "\n",
        "\n",
        "# Create a retriever for few-shot examples\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
        "few_shot_docs = [Document(page_content=question, metadata={\"sql_query\": few_shots[question]}) for question in few_shots.keys()]\n",
        "vector_db = FAISS.from_documents(few_shot_docs, embeddings)\n",
        "retriever = vector_db.as_retriever()\n",
        "\n",
        "# Create a custom tool for retrieving similar examples\n",
        "retriever_tool = create_retriever_tool(retriever, name=\"sql_get_similar_examples\", description=\"Retrieves similar SQL examples, use the YYYY/MM/DD 00:00:00 datetime format.\")\n",
        "\n",
        "# Create the SQL Agent with the custom tool\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    extra_tools=[retriever_tool, date_format_tool],\n",
        "    top_k=30\n",
        ")\n",
        "\n",
        "# Example query using the SQL Agent\n",
        "query_result = agent_executor.run(\n",
        "     \"What was the 30-Year treasury yield on December 20th 2021?\"\n",
        ")\n",
        "print(\"Query Result:\", query_result)"
      ],
      "metadata": {
        "id": "NPSVKyCfvtEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf613ee-27f9-4c1d-e45a-ad48203e5627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input:\n",
            "\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, economic_indicators, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table to get the 30-Year treasury yield.\n",
            "Action: sql_db_schema\n",
            "Action Input: yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TEXT, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use the DateFormatTool to format the date to match the database format.\n",
            "Action: DateFormatTool\n",
            "Action Input: 2021/12/20 00:00:00\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m2021-12-20 00:00:00\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table for the 30-Year treasury yield on December 20th 2021.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT DGS30 FROM yield_curve_prices WHERE Date = '2021-12-20 00:00:00' LIMIT 30\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[(1.85,)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: 1.85\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Result: 1.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Return_Empty_Result.py\n",
        "from __future__ import annotations\n",
        "import warnings\n",
        "from typing import Any, Dict, List, Optional\n",
        "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
        "from langchain.chains.base import Chain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.chains.sql_database.prompt import DECIDER_PROMPT, PROMPT, SQL_PROMPTS\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.schema import BasePromptTemplate\n",
        "from langchain_community.tools.sql_database.prompt import QUERY_CHECKER\n",
        "from langchain_community.utilities.sql_database import SQLDatabase\n",
        "from langchain_core.language_models import BaseLanguageModel\n",
        "from langchain_experimental.pydantic_v1 import Extra, Field, root_validator\n",
        "\n",
        "INTERMEDIATE_STEPS_KEY = \"intermediate_steps\"\n",
        "SQL_QUERY = \"SQLQuery:\"\n",
        "\n",
        "class SQLDatabaseChain(Chain):\n",
        "    llm_chain: LLMChain\n",
        "    llm: Optional[BaseLanguageModel] = None\n",
        "    database: SQLDatabase = Field(exclude=True)\n",
        "    prompt: Optional[BasePromptTemplate] = None\n",
        "    top_k: int = 5\n",
        "    input_key: str = \"query\"\n",
        "    output_key: str = \"result\"\n",
        "    return_sql: bool = False\n",
        "    return_intermediate_steps: bool = False\n",
        "    return_direct: bool = False\n",
        "    use_query_checker: bool = False\n",
        "    query_checker_prompt: Optional[BasePromptTemplate] = None\n",
        "\n",
        "    class Config:\n",
        "        extra = Extra.forbid\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    @root_validator(pre=True)\n",
        "    def raise_deprecation(cls, values: Dict) -> Dict:\n",
        "        if \"llm\" in values:\n",
        "            warnings.warn(\n",
        "                \"Directly instantiating an SQLDatabaseChain with an llm is deprecated. \"\n",
        "                \"Please instantiate with llm_chain argument or using the from_llm \"\n",
        "                \"class method.\"\n",
        "            )\n",
        "            if \"llm_chain\" not in values and values[\"llm\"] is not None:\n",
        "                database = values[\"database\"]\n",
        "                prompt = values.get(\"prompt\") or SQL_PROMPTS.get(\n",
        "                    database.dialect, PROMPT\n",
        "                )\n",
        "                values[\"llm_chain\"] = LLMChain(llm=values[\"llm\"], prompt=prompt)\n",
        "        return values\n",
        "\n",
        "    @property\n",
        "    def input_keys(self) -> List[str]:\n",
        "        return [self.input_key]\n",
        "\n",
        "    @property\n",
        "    def output_keys(self) -> List[str]:\n",
        "        if not self.return_intermediate_steps:\n",
        "            return [self.output_key]\n",
        "        else:\n",
        "            return [self.output_key, INTERMEDIATE_STEPS_KEY]\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        inputs: Dict[str, Any],\n",
        "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
        "    ) -> Dict[str, Any]:\n",
        "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
        "        input_text = f\"{inputs[self.input_key]}\\n{SQL_QUERY}\"\n",
        "        _run_manager.on_text(input_text, verbose=self.verbose)\n",
        "        table_names_to_use = inputs.get(\"table_names_to_use\")\n",
        "        table_info = self.database.get_table_info(table_names=table_names_to_use)\n",
        "        llm_inputs = {\n",
        "            \"input\": input_text,\n",
        "            \"top_k\": str(self.top_k),\n",
        "            \"dialect\": self.database.dialect,\n",
        "            \"table_info\": table_info,\n",
        "            \"stop\": [\"\\nSQLResult:\"],\n",
        "        }\n",
        "        if self.memory is not None:\n",
        "            for k in self.memory.memory_variables:\n",
        "                llm_inputs[k] = inputs[k]\n",
        "        intermediate_steps: List = []\n",
        "        try:\n",
        "            intermediate_steps.append(llm_inputs.copy())  # input: sql generation\n",
        "            sql_cmd = self.llm_chain.predict(\n",
        "                callbacks=_run_manager.get_child(),\n",
        "                **llm_inputs,\n",
        "            ).strip()\n",
        "            if self.return_sql:\n",
        "                return {self.output_key: sql_cmd}\n",
        "            if not self.use_query_checker:\n",
        "                _run_manager.on_text(sql_cmd, color=\"green\", verbose=self.verbose)\n",
        "                intermediate_steps.append(sql_cmd)  # output: sql generation (no checker)\n",
        "                intermediate_steps.append({\"sql_cmd\": sql_cmd})  # input: sql exec\n",
        "                if SQL_QUERY in sql_cmd:\n",
        "                    sql_cmd = sql_cmd.split(SQL_QUERY)[1].strip()\n",
        "                result = self.database.run(sql_cmd)\n",
        "                intermediate_steps.append(str(result))  # output: sql exec\n",
        "            else:\n",
        "                query_checker_prompt = self.query_checker_prompt or PromptTemplate(\n",
        "                    template=QUERY_CHECKER, input_variables=[\"query\", \"dialect\"]\n",
        "                )\n",
        "                query_checker_chain = LLMChain(\n",
        "                    llm=self.llm_chain.llm, prompt=query_checker_prompt\n",
        "                )\n",
        "                query_checker_inputs = {\n",
        "                    \"query\": sql_cmd,\n",
        "                    \"dialect\": self.database.dialect,\n",
        "                }\n",
        "                checked_sql_command: str = query_checker_chain.predict(\n",
        "                    callbacks=_run_manager.get_child(), **query_checker_inputs\n",
        "                ).strip()\n",
        "                intermediate_steps.append(checked_sql_command)  # output: sql generation (checker)\n",
        "                _run_manager.on_text(\n",
        "                    checked_sql_command, color=\"green\", verbose=self.verbose\n",
        "                )\n",
        "                intermediate_steps.append(\n",
        "                    {\"sql_cmd\": checked_sql_command}\n",
        "                )  # input: sql exec\n",
        "                result = self.database.run(checked_sql_command)\n",
        "                intermediate_steps.append(str(result))  # output: sql exec\n",
        "                sql_cmd = checked_sql_command\n",
        "\n",
        "            _run_manager.on_text(\"\\nSQLResult: \", verbose=self.verbose)\n",
        "            _run_manager.on_text(result, color=\"yellow\", verbose=self.verbose)\n",
        "            if self.return_direct:\n",
        "                final_result = result\n",
        "            else:\n",
        "                _run_manager.on_text(\"\\nAnswer:\", verbose=self.verbose)\n",
        "                input_text += f\"{sql_cmd}\\nSQLResult: {result}\\nAnswer:\"\n",
        "                llm_inputs[\"input\"] = input_text\n",
        "                intermediate_steps.append(llm_inputs.copy())  # input: final answer\n",
        "                final_result = self.llm_chain.predict(\n",
        "                    callbacks=_run_manager.get_child(),\n",
        "                    **llm_inputs,\n",
        "                ).strip()\n",
        "                intermediate_steps.append(final_result)  # output: final answer\n",
        "                _run_manager.on_text(final_result, color=\"green\", verbose=self.verbose)\n",
        "            chain_result: Dict[str, Any] = {self.output_key: final_result}\n",
        "            if self.return_intermediate_steps:\n",
        "                chain_result[INTERMEDIATE_STEPS_KEY] = intermediate_steps\n",
        "            return chain_result\n",
        "        except Exception as exc:\n",
        "            exc.intermediate_steps = intermediate_steps  # type: ignore\n",
        "            raise exc\n",
        "\n",
        "    @property\n",
        "    def _chain_type(self) -> str:\n",
        "        return \"sql_database_chain\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm(\n",
        "        cls,\n",
        "        llm: BaseLanguageModel,\n",
        "        db: SQLDatabase,\n",
        "        prompt: Optional[BasePromptTemplate] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> SQLDatabaseChain:\n",
        "        prompt = prompt or SQL_PROMPTS.get(db.dialect, PROMPT)\n",
        "        llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "        return cls(llm_chain=llm_chain, database=db, **kwargs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVVdxdwSQOPc",
        "outputId": "40e58fcc-fe99-493d-8c1d-0120d1a8bc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Return_Empty_Result.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Creation of the vector database with FewShot Examples**"
      ],
      "metadata": {
        "id": "7CsshkHh2GCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.utilities import SQLDatabase\n",
        "#from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from langchain.agents.agent_toolkits import create_retriever_tool\n",
        "import openai\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.utilities import SQLDatabase\n",
        "\n",
        "# Set your OpenAI API key\n",
        "API_KEY=OPENAI_API_KEY\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "# Initialize the SQLite database\n",
        "db_uri = \"sqlite:///financial_data.db\"\n",
        "db = SQLDatabase.from_uri(db_uri)\n",
        "\n",
        "# Initialize the LangChain LLM with OpenAI\n",
        "llm = OpenAI(openai_api_key=API_KEY, temperature=0, verbose=True)\n",
        "\n",
        "# Define few-shot examples specific to your database\n",
        "few_shots = {\n",
        "    \"What was the highest unemployment rate last year?\": \"SELECT MAX(UNRATE) FROM economic_indicators WHERE Date >= '2022-01-01 00:00:00' AND Date <= '2022-12-31 00:00:00';\",\n",
        "    \"Average industrial production for the previous month?\": \"SELECT AVG(IPN213111S) FROM production_data WHERE Date >= date('now', 'start of month', '-1 month') AND Date < date('now', 'start of month');\",\n",
        "    \"Show the five lowest 10-year yield rates of the current year.\": \"SELECT * FROM yield_curve_prices WHERE Date >= '2023-01-01 00:00:00' ORDER BY DGS10 ASC LIMIT 5;\",\n",
        "    \"List the economic indicators for the first quarter of 2023.\": \"SELECT * FROM economic_indicators WHERE Date >= '2023-01-01 00:00:00' AND Date <= '2023-03-31 00:00:00';\",\n",
        "    \"What are the latest available production numbers for Saudi Arabia?\": \"SELECT SAUNGDPMOMBD FROM production_data ORDER BY Date DESC LIMIT 1;\",\n",
        "    \"Compare the unemployment rate at the beginning and end of the last recession.\": \"SELECT UNRATE FROM economic_indicators WHERE Date IN (SELECT Start_Date FROM business_cycles WHERE Phase = 'Contraction' ORDER BY Start_Date DESC LIMIT 1) OR Date IN (SELECT End_Date FROM business_cycles WHERE Phase = 'Contraction' ORDER BY End_Date DESC LIMIT 1);\",\n",
        "    \"Find the average civilian labor force participation rate for the last year.\": \"SELECT AVG(CIVPART) FROM economic_indicators WHERE Date >= '2022-01-01 00:00:00' AND Date <= '2022-12-31 00:00:00';\",\n",
        "    \"Show the change in 2-year yield rates over the past six months.\": \"SELECT DGS2 FROM yield_curve_prices WHERE Date >= date('now', '-6 months') ORDER BY Date;\",\n",
        "    \"What was the maximum production of natural gas in Qatar last year?\": \"SELECT MAX(QATNGDPMOMBD) FROM production_data WHERE Date >= '2022-01-01 00:00:00' AND Date <= '2022-12-31 00:00:00';\",\n",
        "    \"List the top 3 longest economic expansions since 2000.\": \"SELECT Start_Date, End_Date FROM business_cycles WHERE Phase = 'Expansion' AND Start_Date >= '2000-01-01 00:00:00' ORDER BY (julianday(End_Date) - julianday(Start_Date)) DESC LIMIT 3;\"\n",
        "}\n",
        "\n",
        "# Create a retriever for few-shot examples\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
        "few_shot_docs = [Document(page_content=question, metadata={\"sql_query\": few_shots[question]}) for question in few_shots.keys()]\n",
        "vector_db = FAISS.from_documents(few_shot_docs, embeddings)\n",
        "retriever = vector_db.as_retriever()\n",
        "\n",
        "# Create a custom tool for retrieving similar examples\n",
        "retriever_tool = create_retriever_tool(retriever, name=\"sql_get_relevant_examples\", description=\"Retrieves similar SQL examples, please use the 00:00:00 datetime format.\")\n",
        "\n",
        "# Create the SQL Agent with the custom tool\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    extra_tools=[retriever_tool, date_format_tool],\n",
        "    top_k=30\n",
        ")\n",
        "\n",
        "# Example query using the SQL Agent\n",
        "query_result = agent_executor.run(\n",
        "    \"What was the 20-Year treasury yield on January 10th 2006?\"\n",
        ")\n",
        "print(\"Query Result:\", query_result)\n",
        "\n",
        "# Close the database connection\n",
        "conn = sqlite3.connect(db_name)\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "TkgU-xIj2ynt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e68bc9-1af1-405d-8a40-6dbf8328ea81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input:\n",
            "\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, economic_indicators, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table to get the 20-Year treasury yield.\n",
            "Action: sql_db_schema\n",
            "Action Input: yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TEXT, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table for the 20-Year treasury yield on January 10th 2006.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT DGS20 FROM yield_curve_prices WHERE Date = '2006-01-10 00:00:00'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[(4.68,)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: 4.68\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Result: 4.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r5mU5kP7rpnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g6rApqSnpKBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.utilities import SQLDatabase\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.memory import ConversationEntityMemory\n",
        "from langchain.memory.entity import InMemoryEntityStore\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "API_KEY = OPENAI_API_KEY\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "# Initialize the SQLite database\n",
        "db_uri = \"sqlite:///financial_data.db\"\n",
        "db = SQLDatabase.from_uri(db_uri)\n",
        "\n",
        "# Initialize the LangChain LLM with OpenAI\n",
        "llm = OpenAI(openai_api_key=API_KEY, temperature=0.1, verbose=True)\n",
        "\n",
        "# Initialize InMemoryEntityStore for memory\n",
        "entity_store = InMemoryEntityStore()\n",
        "\n",
        "# Initialize ConversationEntityMemory with the LLM and entity store\n",
        "memory = ConversationEntityMemory(llm=llm, entity_store=entity_store)\n",
        "\n",
        "# Create the SQL Agent\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    top_k=5\n",
        ")\n",
        "\n",
        "# Example query using the SQL Agent with Memory\n",
        "query_result = agent_executor.run(\n",
        "    input=\"What was the 3 month yield curve rate on 2007-01-25 00:00:00?\",\n",
        "    memory=memory  # Passing the memory to the agent\n",
        ")\n",
        "\n",
        "print(\"Query Result:\", query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naR_esUROgPr",
        "outputId": "da833824-3fcd-464b-8f8b-d8943ea9e3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAI instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input:\n",
            "\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, economic_indicators, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table to get the 3 month yield curve rate.\n",
            "Action: sql_db_schema\n",
            "Action Input: yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TEXT, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table for the 3 month yield curve rate on 2007-01-25 00:00:00.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT DGS3MO FROM yield_curve_prices WHERE Date = '2007-01-25 00:00:00' LIMIT 5\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[(5.14,)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: 5.14\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Result: 5.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsequent queries can also utilize the memory\n",
        "another_query_result = agent_executor.run(\n",
        "    input=\"What does the average shape of the yield curve in 2023 imply about consumer spending?\",\n",
        "    memory=memory\n",
        ")\n",
        "\n",
        "print(\"Another Query Result:\", another_query_result)\n",
        "\n",
        "# Close the database connection\n",
        "conn = sqlite3.connect(\"financial_data.db\")\n",
        "conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXOF5boGOgSr",
        "outputId": "026c1489-71fd-4098-fe43-4724b8084ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input: \u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, economic_indicators, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the schema of the yield_curve_prices table.\n",
            "Action: sql_db_schema\n",
            "Action Input: yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TIMESTAMP, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the average shape of the yield curve in 2023.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT AVG(DGS1MO), AVG(DGS3MO), AVG(DGS6MO), AVG(DGS1), AVG(DGS2), AVG(DGS3), AVG(DGS5), AVG(DGS7), AVG(DGS10), AVG(DGS20), AVG(DGS30) FROM yield_curve_prices WHERE Date BETWEEN '2023-01-01' AND '2023-12-31'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[(5.145370268700121, 5.273761128162976, 5.280627973378146, 5.082967687215776, 4.586605460801866, 4.3038688015838735, 4.060408912124454, 4.027229914578617, 3.9598342211726965, 4.257743220750071, 4.093981497659846)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The average shape of the yield curve in 2023 implies that consumer spending may decrease, as the average interest rates for shorter-term bonds are higher than those for longer-term bonds. This could indicate a lack of confidence in the economy and a preference for short-term investments.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Another Query Result: The average shape of the yield curve in 2023 implies that consumer spending may decrease, as the average interest rates for shorter-term bonds are higher than those for longer-term bonds. This could indicate a lack of confidence in the economy and a preference for short-term investments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsequent queries can also utilize the memory\n",
        "another_query_result = agent_executor.run(\n",
        "    input=\"How does the current shape of the yield curve impact industrial production?\",\n",
        "    memory=memory\n",
        ")\n",
        "\n",
        "print(\"Another Query Result:\", another_query_result)\n",
        "\n",
        "# Close the database connection\n",
        "conn = sqlite3.connect(\"financial_data.db\")\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "UrM4EaArOgVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be4e447-7681-48b2-9278-2d05cac7ee46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input:\n",
            "\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, economic_indicators, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the schema of the production_data and yield_curve_prices tables.\n",
            "Action: sql_db_schema\n",
            "Action Input: production_data, yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE production_data (\n",
            "\t\"Date\" TIMESTAMP, \n",
            "\t\"SAUNGDPMOMBD\" REAL, \n",
            "\t\"ARENGDPMOMBD\" REAL, \n",
            "\t\"IRNNGDPMOMBD\" REAL, \n",
            "\t\"SAUNXGO\" REAL, \n",
            "\t\"DPCCRV1Q225SBEA\" REAL, \n",
            "\t\"QATNGDPMOMBD\" REAL, \n",
            "\t\"KAZNGDPMOMBD\" REAL, \n",
            "\t\"IRQNXGO\" REAL, \n",
            "\t\"IRNNXGO\" REAL, \n",
            "\t\"KWTNGDPMOMBD\" REAL, \n",
            "\t\"IPN213111S\" REAL, \n",
            "\t\"PCU213111213111\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from production_data table:\n",
            "Date\tSAUNGDPMOMBD\tARENGDPMOMBD\tIRNNGDPMOMBD\tSAUNXGO\tDPCCRV1Q225SBEA\tQATNGDPMOMBD\tKAZNGDPMOMBD\tIRQNXGO\tIRNNXGO\tKWTNGDPMOMBD\tIPN213111S\tPCU213111213111\n",
            "2001-01-01 00:00:00\t7890000.0\t2120000.0\t3571700.0\t7118438.3562\t2.6\t680000.0\t806469.863\t1453907.5448\t2456136.2948\t1745865.7534\t116.4692\t159.6\n",
            "2001-01-02 00:00:00\t7890000.0\t2120000.0\t3571700.0\t7118438.3562\t2.6\t680000.0\t806469.863\t1453907.5448\t2456136.2948\t1745865.7534\t116.4692\t159.6\n",
            "2001-01-03 00:00:00\t7890000.0\t2120000.0\t3571700.0\t7118438.3562\t2.6\t680000.0\t806469.863\t1453907.5448\t2456136.2948\t1745865.7534\t116.4692\t159.6\n",
            "*/\n",
            "\n",
            "\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TIMESTAMP, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the production_data and yield_curve_prices tables to get the relevant data.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT production_data.Date, production_data.SAUNGDPMOMBD, yield_curve_prices.DGS1MO FROM production_data INNER JOIN yield_curve_prices ON production_data.Date = yield_curve_prices.Date ORDER BY yield_curve_prices.DGS1MO DESC LIMIT 5\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[('2023-05-26 00:00:00', 9524004.735891078, 6.02), ('2023-05-27 00:00:00', 9524004.735891078, 6.02), ('2023-05-28 00:00:00', 9524004.735891078, 6.02), ('2023-05-25 00:00:00', 9524004.735891078, 5.95), ('2023-05-11 00:00:00', 9524004.735891078, 5.81)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The current shape of the yield curve does not seem to have a significant impact on industrial production.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Another Query Result: The current shape of the yield curve does not seem to have a significant impact on industrial production.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mabWqWsPW83K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query using the SQL Agent with memory\n",
        "query = \"Describe the average shape of the yield curve in 2023, how does it compare to 2022?\"\n",
        "query_result = agent_executor.run(input=query, memory=memory)\n",
        "print(\"Query Result:\", query_result)"
      ],
      "metadata": {
        "id": "z7QIuK7DFGKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "138b81cb-e0a8-4c60-85a5-34e272b286bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input: \u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, economic_indicators, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the schema of the yield_curve_prices table.\n",
            "Action: sql_db_schema\n",
            "Action Input: yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TEXT, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the average shape of the yield curve in 2023 and compare it to 2022.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT AVG(DGS1MO), AVG(DGS3MO), AVG(DGS6MO), AVG(DGS1), AVG(DGS2), AVG(DGS3), AVG(DGS5), AVG(DGS7), AVG(DGS10), AVG(DGS20), AVG(DGS30) FROM yield_curve_prices WHERE Date LIKE '%2023%'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[(5.146615829607791, 5.2741069880858165, 5.28057145838259, 5.0821650360179245, 4.585628459539395, 4.303063681579535, 4.059805052091236, 4.026826544949634, 3.959615497279073, 4.257585020145276, 4.093806205885436)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should compare the results to the average shape of the yield curve in 2022.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT AVG(DGS1MO), AVG(DGS3MO), AVG(DGS6MO), AVG(DGS1), AVG(DGS2), AVG(DGS3), AVG(DGS5), AVG(DGS7), AVG(DGS10), AVG(DGS20), AVG(DGS30) FROM yield_curve_prices WHERE Date LIKE '%2022%'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[(1.678304970566895, 2.0809858449658396, 2.509016668184099, 2.794539472571261, 2.9828031553761134, 3.043804144210275, 2.9967074692685016, 3.003078184127897, 2.948733064259105, 3.2981365431435368, 3.1121728877374464)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The average shape of the yield curve in 2023 is higher than in 2022.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Result: The average shape of the yield curve in 2023 is higher than in 2022.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query using the SQL Agent with memory\n",
        "query = \"Describe the average shape of the yield curve in 2023, are short term rates higher than long term rates?\"\n",
        "query_result = agent_executor.run(input=query, memory=memory)\n",
        "print(\"Query Result:\", query_result)"
      ],
      "metadata": {
        "id": "967qsyOnHXQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09cc9e44-aaca-4a2a-eb3d-419464153c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input: \u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, economic_indicators, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table to get the average shape of the yield curve in 2023.\n",
            "Action: sql_db_schema\n",
            "Action Input: yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TEXT, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table to get the average shape of the yield curve in 2023.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT AVG(DGS1MO), AVG(DGS3MO), AVG(DGS6MO), AVG(DGS1), AVG(DGS2), AVG(DGS3), AVG(DGS5), AVG(DGS7), AVG(DGS10), AVG(DGS20), AVG(DGS30) FROM yield_curve_prices WHERE Date LIKE '%2023%'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[(5.146615829607791, 5.2741069880858165, 5.28057145838259, 5.0821650360179245, 4.585628459539395, 4.303063681579535, 4.059805052091236, 4.026826544949634, 3.959615497279073, 4.257585020145276, 4.093806205885436)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: Yes, short term rates are higher than long term rates in 2023.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Result: Yes, short term rates are higher than long term rates in 2023.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query using the SQL Agent with memory\n",
        "query = \"Given your previous response, on average was the yield curve inverted in 2023\"\n",
        "query_result = agent_executor.run(input=query, memory=memory)\n",
        "print(\"Query Result:\", query_result)"
      ],
      "metadata": {
        "id": "B7SXL-3dHfSF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5fa4671-0960-4bcd-80b5-a9d4a138679c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input:\n",
            "\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, economic_indicators, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the schema of the yield_curve_prices table.\n",
            "Action: sql_db_schema\n",
            "Action Input: yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TEXT, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table for the average yield curve values in 2023.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT AVG(DGS1MO), AVG(DGS3MO), AVG(DGS6MO), AVG(DGS1), AVG(DGS2), AVG(DGS3), AVG(DGS5), AVG(DGS7), AVG(DGS10), AVG(DGS20), AVG(DGS30) FROM yield_curve_prices WHERE Date LIKE '2023%'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[(5.146615829607791, 5.2741069880858165, 5.28057145838259, 5.0821650360179245, 4.585628459539395, 4.303063681579535, 4.059805052091236, 4.026826544949634, 3.959615497279073, 4.257585020145276, 4.093806205885436)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: [(5.146615829607791, 5.2741069880858165, 5.28057145838259, 5.0821650360179245, 4.585628459539395, 4.303063681579535, 4.059805052091236, 4.026826544949634, 3.959615497279073, 4.257585020145276, 4.093806205885436)]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Result: [(5.146615829607791, 5.2741069880858165, 5.28057145838259, 5.0821650360179245, 4.585628459539395, 4.303063681579535, 4.059805052091236, 4.026826544949634, 3.959615497279073, 4.257585020145276, 4.093806205885436)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "import openai\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.utilities import SQLDatabase\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit, create_retriever_tool\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.memory import ConversationEntityMemory\n",
        "from langchain.memory.entity import InMemoryEntityStore\n",
        "from langchain.memory.chat_message_histories import SQLChatMessageHistory\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "import uuid\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "import redis\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.utilities import SQLDatabase\n",
        "from langchain.memory.chat_message_histories import RedisChatMessageHistory\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from langchain.agents.agent_toolkits import create_retriever_tool\n",
        "from langchain.memory.chat_message_histories import SQLChatMessageHistory\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.memory.chat_message_histories import RedisChatMessageHistory\n",
        "from langchain.utilities import GoogleSearchAPIWrapper\n",
        "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
        "from langchain.utilities import SerpAPIWrapper\n",
        "from langchain.utilities import SQLDatabase\n",
        "from langchain.memory.chat_message_histories import SQLChatMessageHistory\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain_experimental.sql.base import SQLDatabaseSequentialChain\n",
        "import os\n",
        "import uuid\n",
        "from datetime import datetime, timedelta\n",
        "import math\n",
        "import sqlite3\n",
        "from Return_Empty_Result import SQLDatabaseChain\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "serpapi_key = os.getenv(\"SERPAPI_API_KEY\")\n",
        "\n",
        "def generate_session_id(interval_minutes=5):\n",
        "    try:\n",
        "        now = datetime.utcnow()  # Get the current UTC time\n",
        "        minutes_since_midnight = now.hour * 60 + now.minute  # Calculate minutes since midnight\n",
        "        interval_count = math.floor(minutes_since_midnight / interval_minutes)  # Calculate the interval count\n",
        "        session_id = now.strftime(\"%Y%m%d\") + f\"_{interval_count}\"\n",
        "        return session_id\n",
        "    except Exception as e:\n",
        "        print(f\"Error in generating session ID: {e}\")  # Handle exceptions and print an error message\n",
        "        return None  # Return None in case of an error\n",
        "\n",
        "def run_agent_query(agent_executor, query):\n",
        "    try:\n",
        "        return agent_executor.run(input=query)\n",
        "    except openai.BadRequestError as e:\n",
        "        print(f\"Token limit exceeded: {e}\")\n",
        "        return \"Sorry, the query is too long to process.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {type(e).__name__}, {str(e)}\")\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "session_id = generate_session_id()\n",
        "# Initialize InMemoryEntityStore for memory\n",
        "entity_store = InMemoryEntityStore()\n",
        "# Initialize ConversationEntityMemory with the LLM and entity store\n",
        "memory = ConversationEntityMemory(llm=llm, entity_store=entity_store)\n",
        "\n",
        "# Initialize the SQLite database\n",
        "db_uri = \"sqlite:///financial_data.db\"\n",
        "db = SQLDatabase.from_uri(db_uri)\n",
        "sql_tool = Tool(name=\"SQL\", func=retriever_tool.run, description=\"Retrieves similar SQL examples, please use the 00:00:00 datetime format.\")\n",
        "\n",
        "# Add both the SerpAPI and SQL tools to your list of tools\n",
        "tools = [sql_tool]\n",
        "\n",
        "# Use ZeroShotAgent to create the prompt\n",
        "prefix = \"\"\"\n",
        "As an economic data analyst and a SQLite expert, I specialize in interpreting economic indicators and performing data analysis using specific SQL queries.\n",
        "My expertise includes the following tables and their respective fields, you also have access to these tools:\n",
        "\n",
        "1. economic_indicators (DATE, UNRATE, PAYEMS, ICSA, CIVPART, INDPRO)\n",
        "2. yield_curve_prices (Date, DGS1MO, DGS3MO, DGS6MO, DGS1, DGS2, DGS3, DGS5, DGS7, DGS10, DGS20, DGS30)\n",
        "3. production_data (Date, SAUNGDPMOMBD, ARENGDPMOMBD, IRNNGDPMOMBD, SAUNXGO, QATNGDPMOMBD, KAZNGDPMOMBD, IRQNXGO, IRNNXGO, KWTNGDPMOMBD, IPN213111S, PCU213111213111, DPCCRV1Q225SBEA)\n",
        "4. business_cycles (Peak_Month, Trough_Month, Start_Date, End_Date, Phase)\n",
        "\n",
        "Please ask me questions related to these tables and fields. I will use SQL queries and web searches to provide accurate information on economic trends, indicators, and analysis based on this data.\n",
        "Note that my responses are constrained to the data available in these tables. If I do not know an answer, I will say I do not know.\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "Begin!\n",
        "\n",
        "{chat_history}\n",
        "Question: {input}\n",
        "{agent_scratchpad}\n",
        "\"\"\"\n",
        "# Initialize the LangChain LLM with OpenAI\n",
        "llm = OpenAI(openai_api_key=API_KEY, temperature=0, verbose=True)\n",
        "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=False, use_query_checker=True, return_intermediate_steps=False, top_k = 5)\n",
        "prompt = ZeroShotAgent.create_prompt(tools=tools, prefix=prefix, suffix=suffix, input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"])\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Define few-shot examples and create retriever\n",
        "few_shots = {\n",
        "    \"What was the highest unemployment rate last year?\": \"SELECT MAX(UNRATE) FROM economic_indicators WHERE Date >= '2022-01-01' AND Date <= '2022-12-31';\",\n",
        "    \"Average industrial production for the previous month?\": \"SELECT AVG(IPN213111S) FROM production_data WHERE Date >= date('now', 'start of month', '-1 month') AND Date < date('now', 'start of month');\",\n",
        "    \"Show the five lowest 10-year yield rates of the current year.\": \"SELECT * FROM yield_curve_prices WHERE Date >= '2023-01-01' ORDER BY DGS10 ASC LIMIT 5;\",\n",
        "    \"List the economic indicators for the first quarter of 2023.\": \"SELECT * FROM economic_indicators WHERE Date >= '2023-01-01' AND Date <= '2023-03-31';\",\n",
        "    \"What are the latest available production numbers for Saudi Arabia?\": \"SELECT SAUNGDPMOMBD FROM production_data ORDER BY Date DESC LIMIT 1;\",\n",
        "    \"Compare the unemployment rate at the beginning and end of the last recession.\": \"SELECT UNRATE FROM economic_indicators WHERE Date IN (SELECT Start_Date FROM business_cycles WHERE Phase = 'Contraction' ORDER BY Start_Date DESC LIMIT 1) OR Date IN (SELECT End_Date FROM business_cycles WHERE Phase = 'Contraction' ORDER BY End_Date DESC LIMIT 1);\",\n",
        "    \"Find the average civilian labor force participation rate for the last year.\": \"SELECT AVG(CIVPART) FROM economic_indicators WHERE Date >= '2022-01-01' AND Date <= '2022-12-31';\",\n",
        "    \"Show the change in 2-year yield rates over the past six months.\": \"SELECT DGS2 FROM yield_curve_prices WHERE Date >= date('now', '-6 months') ORDER BY Date;\",\n",
        "    \"What was the maximum production of natural gas in Qatar last year?\": \"SELECT MAX(QATNGDPMOMBD) FROM production_data WHERE Date >= '2022-01-01' AND Date <= '2022-12-31';\",\n",
        "    \"List the top 3 longest economic expansions since 2000.\": \"SELECT Start_Date, End_Date FROM business_cycles WHERE Phase = 'Expansion' AND Start_Date >= '2000-01-01' ORDER BY (julianday(End_Date) - julianday(Start_Date)) DESC LIMIT 3;\"\n",
        "}\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
        "few_shot_docs = [Document(page_content=question, metadata={\"sql_query\": few_shots[question]}) for question in few_shots.keys()]\n",
        "vector_db = FAISS.from_documents(few_shot_docs, embeddings)\n",
        "retriever = vector_db.as_retriever()\n",
        "tool_description = \"\"\"\n",
        "This tool will help you get similar SQL examples, please use the 00:00:00 datetime format to adapt them to the user question.\n",
        "Input to this tool should be the user question.\n",
        "\"\"\"\n",
        "# Create a custom tool for retrieving similar examples\n",
        "retriever_tool = create_retriever_tool(retriever, name=\"sql_get_similar_examples\", description=tool_description)\n",
        "\n",
        "# Initialize ConversationEntityMemory and chat history\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "random_session_id = str(uuid.uuid4())\n",
        "engine = create_engine(db_uri)\n",
        "Session = sessionmaker(bind=engine)\n",
        "session = Session()\n",
        "chat_message_history = SQLChatMessageHistory(session_id=random_session_id, connection_string=db_uri)\n",
        "\n",
        "# Create the SQL Agent with memory, chat history, and retriever tool\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm, chat_message_history=chat_message_history)\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    extra_tools=[retriever_tool],\n",
        "    top_k=5\n",
        ")\n",
        "agent = ZeroShotAgent(llm_chain=llm_chain, tools=agent_executor, verbose=True)\n",
        "agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory,  handle_parsing_errors=True)\n",
        "# Add a user message to the chat history and execute query\n",
        "query = \"Describe the yield curve on August 10th 2006. Was the curve inverted?\"\n",
        "query_result = agent_executor.run(input=query)\n",
        "\n",
        "# Print the query result\n",
        "print(\"Query Result:\", query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI2q8ZgzUK95",
        "outputId": "7feacc4c-0d0e-4199-d982-bdff65008a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAI instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.OpenAIEmbeddings instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input:\n",
            "\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, economic_indicators, message_store, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table to get the yield curve data.\n",
            "Action: sql_db_schema\n",
            "Action Input: yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TEXT, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield curve data for August 10th, 2006.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT * FROM yield_curve_prices WHERE Date = '2006-08-10 00:00:00'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[('2006-08-10 00:00:00', 5.12, 5.05, 5.16, 5.08, 4.93, 4.89, 4.86, 4.87, 4.93, 5.15, 5.06)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should check if the curve was inverted by looking at the values for DGS1MO and DGS10.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT DGS1MO, DGS10 FROM yield_curve_prices WHERE Date = '2006-08-10 00:00:00'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[(5.12, 4.93)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Yes, the yield curve was inverted on August 10th, 2006.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Result: Yes, the yield curve was inverted on August 10th, 2006.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.utilities import SQLDatabase\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.memory import ConversationEntityMemory\n",
        "from langchain.memory.entity import InMemoryEntityStore\n",
        "from langchain.memory.chat_message_histories import SQLChatMessageHistory\n",
        "import openai\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from datetime import datetime\n",
        "from sqlalchemy import Column, DateTime, Integer, Text\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from langchain.memory.chat_message_histories.sql import BaseMessageConverter\n",
        "from langchain.schema import HumanMessage, AIMessage, BaseMessage, SystemMessage\n",
        "import uuid\n",
        "\n",
        "# Define the CustomMessage class and CustomMessageConverter\n",
        "Base = declarative_base()\n",
        "\n",
        "class CustomMessage(Base):\n",
        "    __tablename__ = \"custom_message_store\"\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    session_id = Column(Text)\n",
        "    type = Column(Text)\n",
        "    content = Column(Text)\n",
        "    created_at = Column(DateTime)\n",
        "    author_email = Column(Text)\n",
        "\n",
        "Base = declarative_base()\n",
        "\n",
        "class CustomMessage(Base):\n",
        "    __tablename__ = \"custom_message_store\"\n",
        "    id = Column(Integer, primary_key=True)\n",
        "    session_id = Column(Text)\n",
        "    type = Column(Text)\n",
        "    content = Column(Text)\n",
        "    created_at = Column(DateTime)\n",
        "    author_email = Column(Text)\n",
        "\n",
        "class CustomMessageConverter(BaseMessageConverter):\n",
        "    def __init__(self, author_email: str):\n",
        "        self.author_email = author_email\n",
        "\n",
        "    def from_sql_model(self, sql_message: CustomMessage) -> BaseMessage:\n",
        "        if sql_message.type == \"human\":\n",
        "            return HumanMessage(content=sql_message.content)\n",
        "        elif sql_message.type == \"ai\":\n",
        "            return AIMessage(content=sql_message.content)\n",
        "        elif sql_message.type == \"system\":\n",
        "            return SystemMessage(content=sql_message.content)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown message type: {sql_message.type}\")\n",
        "\n",
        "    def to_sql_model(self, message: BaseMessage, session_id: str) -> CustomMessage:\n",
        "        now = datetime.now()\n",
        "        return CustomMessage(\n",
        "            session_id=session_id,\n",
        "            type=message.type,\n",
        "            content=message.content,\n",
        "            created_at=now,\n",
        "            author_email=self.author_email,\n",
        "        )\n",
        "\n",
        "    def get_sql_model_class(self) -> CustomMessage:\n",
        "        return CustomMessage\n",
        "\n",
        "# Define your database connection\n",
        "connection_string = \"sqlite:///financial_data.db\"\n",
        "engine = create_engine(connection_string)\n",
        "Session = sessionmaker(bind=engine)\n",
        "session = Session()\n",
        "\n",
        "# Initialize chat history with custom message converter\n",
        "chat_message_history = SQLChatMessageHistory(\n",
        "    session_id=str(uuid.uuid4()),\n",
        "    connection_string=connection_string,\n",
        "    custom_message_converter=CustomMessageConverter(author_email=\"your_email@example.com\"),\n",
        ")\n",
        "# Create tables\n",
        "Base.metadata.create_all(engine)\n",
        "\n",
        "# Initialize the SQLite database\n",
        "db = SQLDatabase.from_uri(connection_string)\n",
        "\n",
        "# Initialize ConversationEntityMemory with the LLM\n",
        "memory = ConversationEntityMemory(llm=llm, entity_store=InMemoryEntityStore())\n",
        "\n",
        "# Create the SQL Agent\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm, chat_message_history=chat_message_history)\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    top_k=10\n",
        ")\n",
        "\n",
        "# Example query using the SQL Agent with memory\n",
        "query = \"What was the 3 month yield curve rate on 2022-01-25 00:00:00?\"\n",
        "query_result = agent_executor.run(input=query, memory=memory)\n",
        "print(\"Query Result:\", query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoeGS7-tCoZj",
        "outputId": "900bf809-d1bb-4442-966b-5a286e7bfbfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-0447bff709a1>:23: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base = declarative_base()\n",
            "<ipython-input-20-0447bff709a1>:34: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base = declarative_base()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input:\n",
            "\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, custom_message_store, economic_indicators, message_store, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table.\n",
            "Action: sql_db_schema\n",
            "Action Input: yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TIMESTAMP, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the DGS3MO column for the date 2022-01-25.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT DGS3MO FROM yield_curve_prices WHERE Date = '2022-01-25 00:00:00'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[(0.19,)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 0.19\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Result: 0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query using the SQL Agent with memory\n",
        "query = \"Describe the average shape of the yield curve in 2023?\"\n",
        "query_result = agent_executor.run(input=query, memory=memory)\n",
        "print(\"Query Result:\", query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG3zp0kmYSyv",
        "outputId": "21f7ad0b-9789-4c29-fc96-ed23dcf594cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input: \u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, custom_message_store, economic_indicators, message_store, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table to get the average shape of the yield curve.\n",
            "Action: sql_db_schema\n",
            "Action Input: yield_curve_prices\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE yield_curve_prices (\n",
            "\t\"Date\" TIMESTAMP, \n",
            "\t\"DGS1MO\" REAL, \n",
            "\t\"DGS3MO\" REAL, \n",
            "\t\"DGS6MO\" REAL, \n",
            "\t\"DGS1\" REAL, \n",
            "\t\"DGS2\" REAL, \n",
            "\t\"DGS3\" REAL, \n",
            "\t\"DGS5\" REAL, \n",
            "\t\"DGS7\" REAL, \n",
            "\t\"DGS10\" REAL, \n",
            "\t\"DGS20\" REAL, \n",
            "\t\"DGS30\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from yield_curve_prices table:\n",
            "Date\tDGS1MO\tDGS3MO\tDGS6MO\tDGS1\tDGS2\tDGS3\tDGS5\tDGS7\tDGS10\tDGS20\tDGS30\n",
            "2001-01-01 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-02 00:00:00\t3.67\t5.87\t5.58\t5.11\t4.87\t4.82\t4.76\t4.97\t4.92\t5.46\t5.35\n",
            "2001-01-03 00:00:00\t3.67\t5.69\t5.44\t5.04\t4.92\t4.92\t4.94\t5.18\t5.14\t5.62\t5.49\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the yield_curve_prices table for the average shape of the yield curve in 2023.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT AVG(DGS1MO), AVG(DGS3MO), AVG(DGS6MO), AVG(DGS1), AVG(DGS2), AVG(DGS3), AVG(DGS5), AVG(DGS7), AVG(DGS10), AVG(DGS20), AVG(DGS30) FROM yield_curve_prices WHERE Date BETWEEN '2023-01-01' AND '2023-12-31'\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[(5.145370268700121, 5.273761128162976, 5.280627973378146, 5.082967687215776, 4.586605460801866, 4.3038688015838735, 4.060408912124454, 4.027229914578617, 3.9598342211726965, 4.257743220750071, 4.093981497659846)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The average shape of the yield curve in 2023 is [(5.145370268700121, 5.273761128162976, 5.280627973378146, 5.082967687215776, 4.586605460801866, 4.3038688015838735, 4.060408912124454, 4.027229914578617, 3.9598342211726965, 4.257743220750071, 4.093981497659846)].\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Result: The average shape of the yield curve in 2023 is [(5.145370268700121, 5.273761128162976, 5.280627973378146, 5.082967687215776, 4.586605460801866, 4.3038688015838735, 4.060408912124454, 4.027229914578617, 3.9598342211726965, 4.257743220750071, 4.093981497659846)].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example query using the SQL Agent with memory\n",
        "query = \"How about 2024?\"\n",
        "query_result = agent_executor.run(input=query, memory=memory)\n",
        "print(\"Query Result:\", query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKUGH46ZYeOW",
        "outputId": "20aa3f33-cbcc-449c-dccf-18c25fa476ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables\n",
            "Action Input: \u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mbusiness_cycles, custom_message_store, economic_indicators, message_store, production_data, yield_curve_prices\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the schema of the production_data table.\n",
            "Action: sql_db_schema\n",
            "Action Input: production_data\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "CREATE TABLE production_data (\n",
            "\t\"Date\" TIMESTAMP, \n",
            "\t\"SAUNGDPMOMBD\" REAL, \n",
            "\t\"ARENGDPMOMBD\" REAL, \n",
            "\t\"IRNNGDPMOMBD\" REAL, \n",
            "\t\"SAUNXGO\" REAL, \n",
            "\t\"DPCCRV1Q225SBEA\" REAL, \n",
            "\t\"QATNGDPMOMBD\" REAL, \n",
            "\t\"KAZNGDPMOMBD\" REAL, \n",
            "\t\"IRQNXGO\" REAL, \n",
            "\t\"IRNNXGO\" REAL, \n",
            "\t\"KWTNGDPMOMBD\" REAL, \n",
            "\t\"IPN213111S\" REAL, \n",
            "\t\"PCU213111213111\" REAL\n",
            ")\n",
            "\n",
            "/*\n",
            "3 rows from production_data table:\n",
            "Date\tSAUNGDPMOMBD\tARENGDPMOMBD\tIRNNGDPMOMBD\tSAUNXGO\tDPCCRV1Q225SBEA\tQATNGDPMOMBD\tKAZNGDPMOMBD\tIRQNXGO\tIRNNXGO\tKWTNGDPMOMBD\tIPN213111S\tPCU213111213111\n",
            "2001-01-01 00:00:00\t7890000.0\t2120000.0\t3571700.0\t7118438.3562\t2.6\t680000.0\t806469.863\t1453907.5448\t2456136.2948\t1745865.7534\t116.4692\t159.6\n",
            "2001-01-02 00:00:00\t7890000.0\t2120000.0\t3571700.0\t7118438.3562\t2.6\t680000.0\t806469.863\t1453907.5448\t2456136.2948\t1745865.7534\t116.4692\t159.6\n",
            "2001-01-03 00:00:00\t7890000.0\t2120000.0\t3571700.0\t7118438.3562\t2.6\t680000.0\t806469.863\t1453907.5448\t2456136.2948\t1745865.7534\t116.4692\t159.6\n",
            "*/\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should query the production_data table for the relevant columns.\n",
            "Action: sql_db_query\n",
            "Action Input: SELECT Date, SAUNGDPMOMBD, ARENGDPMOMBD, IRNNGDPMOMBD, SAUNXGO, DPCCRV1Q225SBEA, QATNGDPMOMBD, KAZNGDPMOMBD, IRQNXGO, IRNNXGO, KWTNGDPMOMBD, IPN213111S, PCU213111213111 FROM production_data LIMIT 10\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m[('2001-01-01 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-02 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-03 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-04 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-05 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-06 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-07 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-08 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-09 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-10 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6)]\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: [('2001-01-01 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-02 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-03 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Query Result: [('2001-01-01 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-02 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806469.863, 1453907.5448, 2456136.2948, 1745865.7534, 116.4692, 159.6), ('2001-01-03 00:00:00', 7890000.0, 2120000.0, 3571700.0, 7118438.3562, 2.6, 680000.0, 806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile setup_database.py\n",
        "import sqlite3\n",
        "\n",
        "def create_tables(db_name):\n",
        "    with sqlite3.connect(db_name) as conn:\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Create economic indicators table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS economic_indicators (\n",
        "                DATE TEXT PRIMARY KEY,\n",
        "                UNRATE REAL,\n",
        "                PAYEMS REAL,\n",
        "                ICSA REAL,\n",
        "                CIVPART REAL,\n",
        "                INDPRO REAL\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Create yield_curve_prices table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS yield_curve_prices (\n",
        "                Date TEXT PRIMARY KEY,\n",
        "                DGS1MO REAL,\n",
        "                DGS3MO REAL,\n",
        "                DGS6MO REAL,\n",
        "                DGS1 REAL,\n",
        "                DGS2 REAL,\n",
        "                DGS3 REAL,\n",
        "                DGS5 REAL,\n",
        "                DGS7 REAL,\n",
        "                DGS10 REAL,\n",
        "                DGS20 REAL,\n",
        "                DGS30 REAL\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Modify production_data table to match yield_curve_prices schema\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS production_data (\n",
        "                Date TEXT PRIMARY KEY,\n",
        "                SAUNGDPMOMBD REAL,\n",
        "                ARENGDPMOMBD REAL,\n",
        "                IRNNGDPMOMBD REAL,\n",
        "                SAUNXGO REAL,\n",
        "                QATNGDPMOMBD REAL,\n",
        "                KAZNGDPMOMBD REAL,\n",
        "                IRQNXGO REAL,\n",
        "                IRNNXGO REAL,\n",
        "                KWTNGDPMOMBD REAL,\n",
        "                IPN213111S REAL,\n",
        "                PCU213111213111 REAL,\n",
        "                DPCCRV1Q225SBEA REAL\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Create business_cycles table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE business_cycles (\n",
        "                Peak_Month TEXT,\n",
        "                Trough_Month TEXT,\n",
        "                Start_Date TEXT,\n",
        "                End_Date TEXT,\n",
        "                Phase TEXT\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        print(\"Tables created successfully.\")\n",
        "\n",
        "def insert_business_cycle_data(db_name):\n",
        "    business_cycles = [\n",
        "        # [Insert business cycle data here as in your provided code]\n",
        "    ]\n",
        "    with sqlite3.connect(db_name) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        for cycle in business_cycles:\n",
        "            cursor.execute('''\n",
        "                INSERT INTO business_cycles (Peak_Month, Trough_Month, Start_Date, End_Date, Phase)\n",
        "                VALUES (?, ?, ?, ?, ?)\n",
        "            ''', (cycle[\"peak\"], cycle[\"trough\"], cycle[\"start\"], cycle[\"end\"], cycle[\"phase\"]))\n",
        "        print(\"Business cycle data inserted successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_tables(\"financial_data.db\")\n",
        "    insert_business_cycle_data(\"financial_data.db\")"
      ],
      "metadata": {
        "id": "TvuNzVa3YoKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile fetch_insert_data.py\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as web\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, db_name=\"financial_data.db\"):\n",
        "        self.db_name = db_name\n",
        "        self.economic_indicators_tickers = ['UNRATE', 'PAYEMS', 'ICSA', 'CIVPART', 'INDPRO']\n",
        "        self.yield_curve_tickers = ['DGS1MO', 'DGS3MO', 'DGS6MO', 'DGS1', 'DGS2', 'DGS3', 'DGS5', 'DGS7', 'DGS10', 'DGS20', 'DGS30']\n",
        "        self.production_data_tickers = ['SAUNGDPMOMBD', 'ARENGDPMOMBD', 'IRNNGDPMOMBD', 'SAUNXGO', 'DPCCRV1Q225SBEA',\n",
        "                                        'QATNGDPMOMBD', 'KAZNGDPMOMBD', 'IRQNXGO', 'IRNNXGO', 'KWTNGDPMOMBD', 'IPN213111S', 'PCU213111213111']\n",
        "\n",
        "    def fetch_and_insert_data(self, tickers, table_name):\n",
        "        start_date = '2000-12-31'\n",
        "        end_date = datetime.now().strftime('%Y-%m-%d')\n",
        "        try:\n",
        "            data = web.DataReader(tickers, 'fred', start_date, end_date)\n",
        "            data = data.interpolate(method='quadratic').bfill().ffill()\n",
        "            data = data.resample('D').ffill().bfill()\n",
        "\n",
        "            with sqlite3.connect(self.db_name) as conn:\n",
        "                data.to_sql(table_name, conn, if_exists='replace', index_label='Date')\n",
        "            print(f\"Data inserted into {table_name} table\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to fetch and insert the data: {e}\")\n",
        "\n",
        "def main():\n",
        "    db_name = \"financial_data.db\"\n",
        "    loader = DataLoader(db_name)\n",
        "    loader.fetch_and_insert_data(loader.economic_indicators_tickers, 'economic_indicators')\n",
        "    loader.fetch_and_insert_data(loader.yield_curve_tickers, 'yield_curve_prices')\n",
        "    loader.fetch_and_insert_data(loader.production_data_tickers, 'production_data')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "sghtbgouM4K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile initialize_agent.py\n",
        "import redis\n",
        "import openai\n",
        "from dotenv import load_dotenv\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.utilities import SQLDatabase\n",
        "from langchain.memory.chat_message_histories import RedisChatMessageHistory\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from langchain.agents.agent_toolkits import create_retriever_tool\n",
        "from langchain.memory.chat_message_histories import SQLChatMessageHistory\n",
        "import os\n",
        "import uuid\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.memory.chat_message_histories import RedisChatMessageHistory\n",
        "from langchain.utilities import GoogleSearchAPIWrapper\n",
        "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
        "from langchain.utilities import SerpAPIWrapper\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"184cfe6dfee9e06b51ed67cd2df6deda3c566d0e797a3661b7a6c5d8ce1431d4\"\n",
        "serpapi_key = os.getenv(\"SERPAPI_API_KEY\")\n",
        "\n",
        "def initialize_agent(api_key, db_uri):\n",
        "    # Set OpenAI API key\n",
        "    api_key = os.getenv('OPENAI_API_KEY')\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    # Initialize Redis Memory\n",
        "    session_id = str(uuid.uuid4())\n",
        "    message_history = RedisChatMessageHistory(url=\"redis://172.17.0.2:6379/0\", ttl=600, session_id=session_id)\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", chat_memory=message_history)\n",
        "\n",
        "    # Initialize the SerpAPI Wrapper with your API key\n",
        "    search = SerpAPIWrapper(serpapi_api_key=serpapi_key)\n",
        "    serpapi_tool = Tool(name=\"Search\", func=search.run, description=\"useful for when you need to answer questions about the yield curve, finance or economics\")\n",
        "\n",
        "    # Initialize the SQLite database\n",
        "    db = SQLDatabase.from_uri(db_uri)\n",
        "\n",
        "    # Define few-shot examples specific to your database\n",
        "    few_shots = {\n",
        "        \"What was the highest unemployment rate last year?\": \"SELECT MAX(UNRATE) FROM economic_indicators WHERE Date >= '2022-01-01' AND Date <= '2022-12-31';\",\n",
        "        \"Average industrial production for the previous month?\": \"SELECT AVG(IPN213111S) FROM production_data WHERE Date >= date('now', 'start of month', '-1 month') AND Date < date('now', 'start of month');\",\n",
        "        \"Show the five lowest 10-year yield rates of the current year.\": \"SELECT * FROM yield_curve_prices WHERE Date >= '2023-01-01' ORDER BY DGS10 ASC LIMIT 5;\",\n",
        "        \"List the economic indicators for the first quarter of 2023.\": \"SELECT * FROM economic_indicators WHERE Date >= '2023-01-01' AND Date <= '2023-03-31';\",\n",
        "        \"What are the latest available production numbers for Saudi Arabia?\": \"SELECT SAUNGDPMOMBD FROM production_data ORDER BY Date DESC LIMIT 1;\",\n",
        "        \"Compare the unemployment rate at the beginning and end of the last recession.\": \"SELECT UNRATE FROM economic_indicators WHERE Date IN (SELECT Start_Date FROM business_cycles WHERE Phase = 'Contraction' ORDER BY Start_Date DESC LIMIT 1) OR Date IN (SELECT End_Date FROM business_cycles WHERE Phase = 'Contraction' ORDER BY End_Date DESC LIMIT 1);\",\n",
        "        \"Find the average civilian labor force participation rate for the last year.\": \"SELECT AVG(CIVPART) FROM economic_indicators WHERE Date >= '2022-01-01' AND Date <= '2022-12-31';\",\n",
        "        \"Show the change in 2-year yield rates over the past six months.\": \"SELECT DGS2 FROM yield_curve_prices WHERE Date >= date('now', '-6 months') ORDER BY Date;\",\n",
        "        \"What was the maximum production of natural gas in Qatar last year?\": \"SELECT MAX(QATNGDPMOMBD) FROM production_data WHERE Date >= '2022-01-01' AND Date <= '2022-12-31';\",\n",
        "        \"List the top 3 longest economic expansions since 2000.\": \"SELECT Start_Date, End_Date FROM business_cycles WHERE Phase = 'Expansion' AND Start_Date >= '2000-01-01' ORDER BY (julianday(End_Date) - julianday(Start_Date)) DESC LIMIT 3;\"\n",
        "    }\n",
        "\n",
        "    # Create a retriever for few-shot examples\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
        "    few_shot_docs = [Document(page_content=question, metadata={\"sql_query\": few_shots[question]}) for question in few_shots.keys()]\n",
        "    vector_db = FAISS.from_documents(few_shot_docs, embeddings)\n",
        "    retriever = vector_db.as_retriever()\n",
        "\n",
        "    # Create a custom tool for retrieving similar examples\n",
        "    retriever_tool = create_retriever_tool(retriever, name=\"sql_get_similar_examples\", description=\"Retrieves similar SQL examples.\")\n",
        "\n",
        "    # Define the SQL tool\n",
        "    sql_tool = Tool(name=\"SQL\", func=retriever_tool.run, description=\"useful for querying financial data from the database\")\n",
        "\n",
        "    # Add both the SerpAPI and SQL tools to your list of tools\n",
        "    tools = [serpapi_tool, sql_tool]\n",
        "\n",
        "    # Use ZeroShotAgent to create the prompt\n",
        "    prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
        "    suffix = \"\"\"Begin!\\n\\n{chat_history}\\nQuestion: {input}\\n{agent_scratchpad}\"\"\"\n",
        "    prompt = ZeroShotAgent.create_prompt(tools=tools, prefix=prefix, suffix=suffix, input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"])\n",
        "\n",
        "    # Initialize the LangChain LLM with OpenAI\n",
        "    llm = OpenAI(openai_api_key=api_key, temperature=0.2, verbose=True)\n",
        "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "    agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
        "    agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)\n",
        "\n",
        "    return agent_chain\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "    db_uri = \"sqlite:///financial_data.db\"\n",
        "    agent_executor = initialize_agent(API_KEY, db_uri)\n",
        "\n",
        "    # Example query using the agent\n",
        "    query_result = agent_executor.run(input=\"Based on the yield curve, did the economy appear to be in an expansionary phase in 2017, and why?\")\n",
        "    print(\"Query Result:\", query_result)\n"
      ],
      "metadata": {
        "id": "JciIonEmMhvZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}